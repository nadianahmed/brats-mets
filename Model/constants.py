ATTENTION_BLOCK_TEMPLATE_CHANNELS = 1

ATTENTION_U_NET_FEATURES_PER_LAYER = [32, 64, 128, 256]
ATTENTION_U_NET_CONVOLUTION_KERNEL_SIZE = 3
ATTENTION_U_NET_CONVOLUTION_PADDING_SIZE = 1
ATTENTION_U_NET_TRANSPOSED_CONVOLUTION_KERNEL_SIZE = 2
ATTENTION_U_NET_TRANSPOSED_CONVOLUTION_PADDING_SIZE = 1
ATTENTION_U_NET_OUTPUT_CONVOLUTION_KERNEL_SIZE = 1
ATTENTION_U_NET_NUM_INPUT_CHANNELS = 1
ATTENTION_U_NET_NUM_OUTPUT_CHANNELS = 2
ATTENTION_U_NET_LEARNING_RATE = 1e-4
ATTENTION_U_NET_CLASS_WEIGHTS = [0.1, 1.0]

SMOOTHNESS_FACTOR = 1e-5
NUM_CLASSES = 2